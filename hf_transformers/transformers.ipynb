{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32844295",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#%pip install transformers\n",
    "#%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "#%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1478532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the QA pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "def answer_question(question, context):\n",
    "    \"\"\"\n",
    "    Answers a question based on the given context using a pre-trained QA model.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to be answered.\n",
    "        context (str): The context in which the question should be answered.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the answer and other information.\n",
    "    \"\"\"\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example context\n",
    "context = \"\"\"\n",
    "The phenomenon of why the sky appears blue is primarily due to a process called Rayleigh scattering.\n",
    "Extractive Question Answering is the task of extracting an answer from a given text. \n",
    "An example of a question answering dataset is the SQuAD dataset which is entirely based on that task.\n",
    "\"\"\"\n",
    "\n",
    "# Example questions\n",
    "questions = [\n",
    "    \"What is the task of extractive question answering?\",\n",
    "    \"Which dataset is entirely based on extractive QA?\",\n",
    "    \"Why the sky is blue?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    answer = answer_question(question, context)\n",
    "    print(f\"Answer: {answer['answer']}\")\n",
    "    print(f\"Score: {answer['score']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis model\n",
    "model = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Initialize the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model)\n",
    "\n",
    "# Get input from user\n",
    "text = \"\"#input(\"Enter a sentence to analyze: \").strip()\n",
    "\n",
    "# If no text entered, use a default example\n",
    "if not text:\n",
    "    text = \"I love this product!\"\n",
    "\n",
    "# Analyze sentiment of the input text\n",
    "result = sentiment_pipeline(text)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nSentiment Analysis Results:\")\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Sentiment Label: {result[0]['label']}\")\n",
    "print(f\"Confidence Score: {result[0]['score']:.4f}\")\n",
    "\n",
    "# Optional: Add emoji based on sentiment\n",
    "emoji = \"ðŸ˜Š\" if result[0]['label'] == 'positive' else \"ðŸ˜”\"\n",
    "print(f\"Emoji Representation: {emoji}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9159de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install matplotlib\n",
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install torch\n",
    "# %pip install git+https://github.com/amazon-science/chronos-forecasting.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b013d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "  \"amazon/chronos-t5-large\",\n",
    "  device_map=\"cuda\",\n",
    "  torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\")\n",
    "\n",
    "# context must be either a 1D tensor, a list of 1D tensors,\n",
    "# or a left-padded 2D tensor with batch as the first dimension\n",
    "context = torch.tensor(df[\"#Passengers\"])\n",
    "prediction_length = 48\n",
    "forecast = pipeline.predict(context, prediction_length)  # shape [num_series, num_samples, prediction_length]\n",
    "\n",
    "# visualize the forecast\n",
    "forecast_index = range(len(df), len(df) + prediction_length)\n",
    "low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df[\"#Passengers\"], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
