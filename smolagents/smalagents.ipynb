{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/smolagents/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"smolagents[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import LiteLLMModel\n",
    "\n",
    "model = LiteLLMModel(\n",
    "    model_id=\"ollama_chat/phi4:latest\", \n",
    "    api_base=\"http://localhost:11434\",\n",
    "    #api_key=\"YOUR_API_KEY\", # replace with API key if necessary\n",
    "    num_ctx=24576, # ollama default is 2048 which will fail horribly. 8192 works for easy tasks, more is better. Check https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator to calculate how much VRAM this will need for the selected model.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from smolagents import CodeAgent\n",
    "\n",
    "# # # executor_type=\"docker\"\n",
    "# agent = CodeAgent(tools=[], model=model, add_base_tools=True, additional_authorized_imports=['requests', 'bs4'])\n",
    "# agent.run(\"Could you give me the 118th number in the Fibonacci sequence?\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from smolagents import ToolCallingAgent\n",
    "# from smolagents import GradioUI\n",
    "\n",
    "# agent = ToolCallingAgent(tools=[], model=model, add_base_tools=True)\n",
    "# # agent.run(\"Why the sky is blue?\")\n",
    "# GradioUI(agent).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b2899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from smolagents import CodeAgent, WebSearchTool\n",
    "\n",
    "# web_agent = CodeAgent(\n",
    "#     tools=[WebSearchTool()],\n",
    "#     model=model,\n",
    "#     name=\"web_search_1\",\n",
    "#     description=\"Runs web searches for you. Give it your query as an argument.\"\n",
    "# )\n",
    "\n",
    "# manager_agent = CodeAgent(\n",
    "#     tools=[], model=model, managed_agents=[web_agent]\n",
    "# )\n",
    "\n",
    "# manager_agent.run(\"Who is the CEO of Hugging Face?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc207d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from smolagents import (\n",
    "#     load_tool,\n",
    "#     CodeAgent,\n",
    "#     InferenceClientModel,\n",
    "#     GradioUI\n",
    "# )\n",
    "\n",
    "# # Import tool from Hub\n",
    "# image_generation_tool = load_tool(\"m-ric/text-to-image\", trust_remote_code=True)\n",
    "\n",
    "# # Initialize the agent with the image generation tool\n",
    "# agent = CodeAgent(tools=[image_generation_tool], model=model)\n",
    "\n",
    "# GradioUI(agent).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b56741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
